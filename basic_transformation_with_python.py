# -*- coding: utf-8 -*-
"""Basic_transformation_with_python.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UpZHxwn0B819Sx2T0_pLSp0Tu5bRTl_p
"""

!wget https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz
!tar -xvf spark-3.2.1-bin-hadoop3.2.tgz
import os 
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-11-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.2.1-bin-hadoop3.2"
!pip install findspark
import findspark 
findspark.init()
from pyspark.sql import SparkSession
from pyspark import SparkContext
spark = SparkSession.builder.master("local[*]").getOrCreate()

!wget https://raw.githubusercontent.com/futurexskill/bigdata/master/bank_prospects.csv

bankdf= spark.read.csv("bank_prospects.csv",header=True)

bankdf.show()

from pyspark.sql.types import IntegerType, FloatType
bankdf2 = bankdf.withColumn("age", bankdf["Age"].cast(IntegerType())).withColumn("salary",bankdf["Salary"].cast(FloatType()))

bankdf2.printSchema()

from pyspark.sql.functions import mean 
mean_age = bankdf2.select(mean(bankdf2["age"])).collect()

type(mean_age)

mean_age

mean_age_val= mean_age[0][0]

mean_age_val

mean_salary = bankdf2.select(mean(bankdf2["salary"])).collect()

mean_salary_value = mean_salary[0][0]

mean_salary_value

bankdf3 = bankdf2.na.fill(mean_age_val,["age"])

bankdf3.show()

bankdf4 = bankdf3.na.fill(mean_salary_value,["salary"])

bankdf4.show()

bankdf5= bankdf4.filter(bankdf["Country"]!="unknown")

bankdf5.show()

bankdf5.write.format("csv").save("Bank_transformed")

